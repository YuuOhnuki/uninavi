"""
AI Search Service
Uses Tavily/Serper API to search for university information
and Hugging Face Chat Completions API for summarization
"""

import os
import json
import logging
import time
import asyncio
import contextlib
from textwrap import dedent
from typing import Awaitable, Callable, Dict, Any, AsyncIterator, List, Optional
import httpx

from dotenv import load_dotenv # ğŸ‘ˆ è¿½åŠ 

# ğŸš¨ ã€ä¿®æ­£ã€‘ç’°å¢ƒå¤‰æ•°ãƒ­ãƒ¼ãƒ‰
load_dotenv() # ğŸ‘ˆ è¿½åŠ : .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logger = logging.getLogger(__name__)

IS_DEV = os.getenv("UNINAVI_ENV") == "development" or os.getenv("NODE_ENV") == "development"


def _debug_log(message: str) -> None:
    if IS_DEV:
        logger.debug(message)

# ğŸš¨ ã€ä¿®æ­£ç®‡æ‰€ã€‘Hugging Face Chat Completions API configuration
# ğŸ“ ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã«åˆã‚ã›ã¦URLã¨ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
HF_API_KEY = os.getenv("HF_API_KEY", "")
# Chat Completions APIã®URL
HUGGINGFACE_API_URL = "https://router.huggingface.co/v1/chat/completions"
# Chat Completions APIã§åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªã«å¼·ã„Instructãƒ¢ãƒ‡ãƒ«
# å„ªå…ˆé †ä½: ç„¡æ–™/ä½ã‚³ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’å„ªå…ˆ
PREFERRED_MODELS = [
    "MiniMaxAI/MiniMax-M2:novita",  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã€ä½ã‚³ã‚¹ãƒˆ
    "Qwen/Qwen2.5-7B-Instruct:together",  # ä»£æ›¿
    "microsoft/WizardLM-2-8x22B",  # é«˜æ€§èƒ½
]

HUGGINGFACE_MODEL_ID = os.getenv("HF_MODEL_ID", "")

async def select_optimal_model() -> str:
    """
    Automatically select the optimal HuggingFace model based on availability and priority.
    Tests each model by making a small API call and returns the first working one.
    """
    if not HF_API_KEY:
        logger.warning("No HF API key configured")
        return PREFERRED_MODELS[0]  # Return default if no key

    # If explicitly set in env, use that
    if HUGGINGFACE_MODEL_ID:
        logger.info(f"Using explicitly set model: {HUGGINGFACE_MODEL_ID}")
        return HUGGINGFACE_MODEL_ID

    headers = {
        "Authorization": f"Bearer {HF_API_KEY}",
        "Content-Type": "application/json"
    }

    test_payload = {
        "messages": [{"role": "user", "content": "Hello"}],
        "max_tokens": 10,
        "temperature": 0.1,
    }

    for model in PREFERRED_MODELS:
        try:
            logger.debug(f"Testing model: {model}")
            test_payload["model"] = model
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.post(
                    HUGGINGFACE_API_URL,
                    headers=headers,
                    json=test_payload,
                )
                if response.status_code == 200:
                    result = response.json()
                    if 'choices' in result and result['choices']:
                        logger.info(f"Selected optimal model: {model}")
                        return model
                else:
                    logger.debug(f"Model {model} failed with status {response.status_code}")
        except Exception as e:
            logger.debug(f"Model {model} test failed: {str(e)}")
            continue

    # Fallback to first model if all fail
    logger.warning("All models failed, using fallback")
    return PREFERRED_MODELS[0]

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ã—ã¦é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ä¿æŒ
SELECTED_MODEL = None

async def initialize_model():
    global SELECTED_MODEL
    if SELECTED_MODEL is None:
        SELECTED_MODEL = await select_optimal_model()
    return SELECTED_MODEL

# Tavily API (alternative: Serper.dev)
TAVILY_API_KEY = os.getenv("TAVILY_API_KEY", "")
SERPER_API_KEY = os.getenv("SERPER_API_KEY", "")

logger.info(f"Hugging Face Model ID: {HUGGINGFACE_MODEL_ID}")
logger.info(f"Tavily API Key configured: {bool(TAVILY_API_KEY)}")
logger.info(f"Serper API Key configured: {bool(SERPER_API_KEY)}")


JSON_OUTPUT_EXAMPLE = dedent(
    """
    [
      {
        "id": "unique-id",
        "name": "å¤§å­¦å",
        "officialUrl": "å…¬å¼ã‚µã‚¤ãƒˆURL",
        "faculty": "å­¦éƒ¨å",
        "department": "å­¦ç§‘å",
        "deviationScore": "åå·®å€¤ï¼ˆä¾‹: 60-65ï¼‰",
        "commonTestScore": "å…±ãƒ†å¾—ç‚¹ç‡ï¼ˆä¾‹: 75-80%ï¼‰",
        "examType": "å…¥è©¦å½¢æ…‹",
        "requiredSubjects": ["ç§‘ç›®1", "ç§‘ç›®2"],
        "examDate": "è©¦é¨“æ—¥",
        "examSchedules": ["é¡˜æ›¸å—ä»˜: YYYYå¹´MMæœˆDDæ—¥", "è©¦é¨“æ—¥: YYYYå¹´MMæœˆDDæ—¥"],
        "admissionMethods": ["ä¸€èˆ¬é¸æŠœ: å‰æœŸæ—¥ç¨‹ 2ç§‘ç›®å‹", "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹: è‹±èªé‡è¦–"],
        "subjectHighlights": ["æ•°å­¦: 200ç‚¹ï¼ˆå…±é€šãƒ†ã‚¹ãƒˆæ›ç®—ï¼‰", "ç†ç§‘: 150ç‚¹ï¼ˆåŒ–å­¦/ç‰©ç†ã‹ã‚‰é¸æŠ)"],
        "commonTestRatio": "å…±é€šãƒ†ã‚¹ãƒˆ 60% / å€‹åˆ¥è©¦é¨“ 40%",
        "selectionNotes": "æŒ‡å®šæ ¡æ¨è–¦æ ã‚ã‚Šã€‚å…±ãƒ†åˆ©ç”¨å‹ã¯è‹±èªå¤–éƒ¨è©¦é¨“å¾—ç‚¹æ›ç®—å¯ã€‚",
        "applicationDeadline": "2025å¹´1æœˆ15æ—¥",
        "institutionType": "å›½ç«‹",
        "aiSummary": "å¤§å­¦ãƒ»å­¦éƒ¨ã®ç‰¹å¾´ã‚„å¼·ã¿ã‚’100æ–‡å­—ç¨‹åº¦ã§å…·ä½“çš„ã«è¦ç´„ï¼ˆè¤‡æ•°ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®è¦ç´ ã‚’çµ±åˆï¼‰",
        "sources": ["å‡ºå…¸URL1", "å‡ºå…¸URL2"]
      }
    ]
    """
)


def _to_string(value: Any) -> str:
    if value is None:
        return ""
    if isinstance(value, str):
        return value.strip()
    return str(value).strip()


def _ensure_list_of_strings(value: Any) -> List[str]:
    if isinstance(value, list):
        return [item for item in (_to_string(v) for v in value) if item]
    string_value = _to_string(value)
    if not string_value:
        return []
    # Allow comma or newline separated strings
    separators = ["\n", ",", "ãƒ»", "ï¼Œ", "ã€"]
    for separator in separators:
        if separator in string_value:
            return [item.strip() for item in string_value.split(separator) if item.strip()]
    return [string_value]


def _format_url(url: str) -> str:
    if not url:
        return ""
    cleaned = url.strip()
    if not cleaned:
        return ""
    if cleaned.startswith("http://") or cleaned.startswith("https://"):
        return cleaned
    if cleaned.startswith("//"):
        return f"https:{cleaned}"
    if cleaned.startswith("www."):
        return f"https://{cleaned}"
    return f"https://{cleaned}"


def _select_official_url(candidate: Any, sources: Any) -> str:
    candidates: List[str] = []
    candidate_str = _to_string(candidate)
    if candidate_str:
        candidates.append(candidate_str)

    for source in _ensure_list_of_strings(sources):
        candidates.append(source)

    seen: set[str] = set()
    prioritized: List[str] = []
    for value in candidates:
        formatted = _format_url(value)
        if not formatted or formatted in seen:
            continue
        seen.add(formatted)
        prioritized.append(formatted)

    if not prioritized:
        return ""

    prioritized.sort(key=lambda url: (-100 if ".ac.jp" in url else -50 if "admissions" in url else -10 if url.startswith("https://www.") else 0))
    return prioritized[0]


def _normalize_university_entry(entry: dict) -> dict:
    entry = dict(entry)
    entry.setdefault("requiredSubjects", [])
    entry.setdefault("sources", [])
    entry.setdefault("examSchedules", [])
    entry.setdefault("admissionMethods", [])
    entry.setdefault("subjectHighlights", [])

    entry["requiredSubjects"] = _ensure_list_of_strings(entry.get("requiredSubjects"))
    entry["sources"] = _ensure_list_of_strings(entry.get("sources"))
    entry["examSchedules"] = _ensure_list_of_strings(entry.get("examSchedules"))
    entry["admissionMethods"] = _ensure_list_of_strings(entry.get("admissionMethods"))
    entry["subjectHighlights"] = _ensure_list_of_strings(entry.get("subjectHighlights"))

    entry["officialUrl"] = _select_official_url(entry.get("officialUrl"), entry.get("sources"))
    entry["commonTestRatio"] = _to_string(entry.get("commonTestRatio"))
    entry["selectionNotes"] = _to_string(entry.get("selectionNotes"))
    entry["applicationDeadline"] = _to_string(entry.get("applicationDeadline"))
    entry["examDate"] = _to_string(entry.get("examDate"))
    entry["aiSummary"] = _to_string(entry.get("aiSummary"))
    entry["faculty"] = _to_string(entry.get("faculty"))
    entry["department"] = _to_string(entry.get("department"))
    entry["examType"] = _to_string(entry.get("examType"))
    entry["deviationScore"] = _to_string(entry.get("deviationScore"))
    entry["commonTestScore"] = _to_string(entry.get("commonTestScore"))
    entry["name"] = _to_string(entry.get("name"))

    return entry


# ğŸš¨ ã€ä¿®æ­£ç®‡æ‰€ã€‘Hugging Face Chat Completions APIã®ã‚¯ã‚¨ãƒªé–¢æ•°
async def query_hf_inference(messages: List[Dict[str, str]], max_retries: int = 3, initial_delay: float = 1.0) -> Dict[str, Any]:
    """
    Send a query to Hugging Face Chat Completions API with retry logic
    """
    if not HF_API_KEY:
        raise ValueError("Hugging Face API key not configured")
        
    headers = {
        "Authorization": f"Bearer {HF_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # ğŸš¨ ã€ä¿®æ­£ç®‡æ‰€ã€‘ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’ Chat Completions API å½¢å¼ã«å¤‰æ›´
    payload = {
        "messages": messages, # 'messages' å½¢å¼ã®å…¥åŠ›ã‚’ãã®ã¾ã¾ä½¿ç”¨
        "model": SELECTED_MODEL or HUGGINGFACE_MODEL_ID or PREFERRED_MODELS[0],
        "temperature": 0.2, # æ§‹é€ åŒ–ã•ã‚ŒãŸJSONå‡ºåŠ›ã‚’å¾—ã‚‹ãŸã‚ã€æ¸©åº¦ã‚’ä½ã‚ã«è¨­å®š
        "max_tokens": 2000, # è¿”å´ä»¶æ•°ã‚’å¢—ã‚„ã™ãŸã‚å°‘ã—æ‹¡å¤§
        "top_p": 0.9,
    }
    
    async with httpx.AsyncClient(timeout=120.0) as client:
        delay = initial_delay
        for attempt in range(max_retries):
            try:
                response = await client.post(
                    HUGGINGFACE_API_URL,
                    headers=headers,
                    json=payload,
                )
                
                if response.status_code == 200:
                    result = response.json()
                    # å¿œç­”å½¢å¼ã¯ {"choices": [{"message": {"role": "...", "content": "..."}}]}
                    if 'choices' in result and result['choices'] and 'message' in result['choices'][0]:
                        # å½¢å¼ã¯ãã®ã¾ã¾è¿”å´ (summarize_with_aiã§åˆ©ç”¨ã™ã‚‹ãŸã‚)
                        return result
                    else:
                        raise ValueError(f"Unexpected HF response format: {result}")
                
                elif response.status_code == 429 or response.status_code >= 500: # Rate limited or server error
                    retry_after = float(response.headers.get("Retry-After", delay * 2))
                    logger.warning(f"Rate limited/Server error. Retrying after {retry_after:.2f} seconds...")
                    await asyncio.sleep(retry_after)
                    delay *= 2
                    
                else:
                    logger.error(f"HF Chat API error: {response.status_code} - {response.text}")
                    response.raise_for_status() # 4xxã‚¨ãƒ©ãƒ¼ã¯å³åº§ã«ä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã‚‹

            except Exception as e:
                logger.error(f"Error querying HF Chat API: {str(e)}")
                if attempt == max_retries - 1:
                    raise
                await asyncio.sleep(delay)
                delay *= 2
    
    raise Exception("Failed to get response from HF Chat API after multiple retries")


# search_web é–¢æ•°ã¯å¤‰æ›´ãªã—

async def search_web(query: str) -> List[dict]:
    """
    Search the web using Tavily or Serper API
    Returns list of search results
    """
    logger.info(f"Searching web for query: {query}")
    
    _debug_log(f"[search_web] starting aggregated search for query='{query}'")

    async def _search_tavily() -> List[dict]:
        if not TAVILY_API_KEY:
            return []
        logger.debug("Attempting Tavily search...")
        try:
            async with httpx.AsyncClient(timeout=30.0) as http_client:
                response = await http_client.post(
                    "https://api.tavily.com/search",
                    json={"api_key": TAVILY_API_KEY, "query": query, "max_results": 20},
                )
            if response.status_code == 200:
                data = response.json()
                results = data.get("results", [])
                logger.info(f"Tavily search successful, found {len(results)} results")
                _debug_log(f"[search_web] Tavily returned {len(results)} results")
                return results
            logger.warning(f"Tavily search returned status {response.status_code}: {response.text}")
        except Exception as exc:  # noqa: BLE001
            logger.error(f"Tavily search failed: {exc}")
        return []

    async def _search_serper() -> List[dict]:
        if not SERPER_API_KEY:
            return []
        logger.debug("Attempting Serper search...")
        try:
            async with httpx.AsyncClient(timeout=30.0) as http_client:
                response = await http_client.post(
                    "https://google.serper.dev/search",
                    json={"q": query, "num": 20},
                    headers={"X-API-KEY": SERPER_API_KEY},
                )
            if response.status_code == 200:
                data = response.json()
                organic = data.get("organic", [])
                logger.info(f"Serper search successful, found {len(organic)} results")
                _debug_log(f"[search_web] Serper returned {len(organic)} results")
                return [
                    {
                        "title": item.get("title", ""),
                        "url": item.get("link", ""),
                        "content": item.get("snippet", ""),
                    }
                    for item in organic
                ]
            logger.warning(f"Serper search returned status {response.status_code}: {response.text}")
        except Exception as exc:  # noqa: BLE001
            logger.error(f"Serper search failed: {exc}")
        return []

    tasks: List[tuple[str, asyncio.Task[List[dict]]]] = []
    if TAVILY_API_KEY:
        tasks.append(("tavily", asyncio.create_task(_search_tavily())))
    if SERPER_API_KEY:
        tasks.append(("serper", asyncio.create_task(_search_serper())))

    if not tasks:
        logger.warning("No search providers configured. Returning empty results.")
        return []

    results_by_priority: dict[str, List[dict]] = {label: [] for label, _ in tasks}
    responses = await asyncio.gather(*(task for _, task in tasks), return_exceptions=True)
    for (label, _), response in zip(tasks, responses, strict=True):
        if isinstance(response, Exception):
            logger.error(f"Search task '{label}' raised an exception: {response}")
            continue
        results_by_priority[label] = response

    merged_results: List[dict] = []
    seen_urls: set[str] = set()
    for label in ("tavily", "serper"):
        for item in results_by_priority.get(label, []):
            url = item.get("url") or item.get("link") or ""
            if url and url not in seen_urls:
                merged_results.append(item)
                seen_urls.add(url)

    if merged_results:
        logger.info(f"Search aggregation complete. Returning {len(merged_results)} merged results")
        _debug_log(f"[search_web] merged unique results={len(merged_results)}")
        return merged_results

    logger.warning("All search providers returned empty results")
    return []


# summarize_with_ai é–¢æ•°ã¯ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãã®ã¾ã¾ç¶­æŒã—ã€APIå‘¼ã³å‡ºã—ã®ã¿å¤‰æ›´

async def filter_universities_by_conditions(
    universities: List[dict],
    filters: Dict[str, str],
    progress_callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
    university_callback: Optional[Callable[[dict], Awaitable[None]]] = None,
) -> List[dict]:
    """
    Filter universities based on search conditions using AI verification
    """
    if not HF_API_KEY:
        logger.warning("No Hugging Face API key configured for filtering")
        return universities

    if not universities:
        return universities

    logger.info(f"Filtering {len(universities)} universities with AI verification")

    async def _emit_progress(stage: str, detail: Optional[Dict[str, Any]] = None) -> None:
        if progress_callback is None:
            return
        payload = {"stage": stage}
        if detail:
            payload.update(detail)
        await progress_callback(payload)

    await _emit_progress("filtering", {"total": len(universities)})

    # Parallel filtering of universities
    semaphore = asyncio.Semaphore(5)  # Limit concurrent AI calls to avoid rate limits

    async def _filter_single_university(university: dict) -> Optional[dict]:
        async with semaphore:
            # Build verification prompt
            system_prompt = """ã‚ãªãŸã¯æ—¥æœ¬ã®å¤§å­¦å—é¨“ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸå¤§å­¦æƒ…å ±ã¨æ¤œç´¢æ¡ä»¶ã‚’æ¯”è¼ƒã—ã€ã“ã®å¤§å­¦ãŒæ¡ä»¶ã«åˆã£ã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚
å›ç­”ã¯å¿…ãšJSONå½¢å¼ã§ã€{"matches": true/false, "reason": "ç†ç”±ã®èª¬æ˜"} ã®å½¢å¼ã«ã—ã¦ãã ã•ã„ã€‚"""

            university_info = f"""
å¤§å­¦å: {university.get('name', '')}
å­¦éƒ¨: {university.get('faculty', '')}
å­¦ç§‘: {university.get('department', '')}
åå·®å€¤: {university.get('deviationScore', '')}
å…±ãƒ†å¾—ç‚¹ç‡: {university.get('commonTestScore', '')}
å…¥è©¦å½¢æ…‹: {university.get('examType', '')}
å¿…è¦ç§‘ç›®: {', '.join(university.get('requiredSubjects', []))}
åœ°åŸŸ: {university.get('region', '')}
éƒ½é“åºœçœŒ: {university.get('prefecture', '')}
"""

            search_conditions = f"""
æ¤œç´¢æ¡ä»¶:
åœ°åŸŸ: {filters.get('region', '')}
å­¦éƒ¨: {filters.get('faculty', '')}
å…¥è©¦å½¢æ…‹: {filters.get('exam_type', '')}
å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨: {filters.get('use_common_test', '')}
åå·®å€¤: {filters.get('deviation_score', '')}
æ©Ÿé–¢ç¨®åˆ¥: {filters.get('institution_type', '')}
éƒ½é“åºœçœŒ: {filters.get('prefecture', '')}
å¤§å­¦åã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {filters.get('name_keyword', '')}
å…±ãƒ†å¾—ç‚¹ç‡: {filters.get('common_test_score', '')}
è‹±èªå¤–éƒ¨è©¦é¨“: {filters.get('external_english', '')}
å¿…è¦ç§‘ç›®: {filters.get('required_subjects', '')}
å­¦è²»ä¸Šé™: {filters.get('tuition_max', '')}
å¥¨å­¦é‡‘: {filters.get('scholarship', '')}
è³‡æ ¼å–å¾—: {filters.get('qualification', '')}
å…¥è©¦æ—¥ç¨‹: {filters.get('exam_schedule', '')}
"""

            user_prompt = f"""ä»¥ä¸‹ã®å¤§å­¦æƒ…å ±ã¨æ¤œç´¢æ¡ä»¶ã‚’æ¯”è¼ƒã—ã€ã“ã®å¤§å­¦ãŒæ¤œç´¢æ¡ä»¶ã«åˆã£ã¦ã„ã‚‹ã‹ã‚’åˆ¤å®šã—ã¦ãã ã•ã„ã€‚

{university_info}

{search_conditions}

æ¡ä»¶ã«åˆã£ã¦ã„ã‚‹å ´åˆã¯ trueã€åˆã£ã¦ã„ãªã„å ´åˆã¯ false ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
åˆ¤å®šç†ç”±ã‚‚ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"""

            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ]

            try:
                response_data = await query_hf_inference(messages, max_retries=2, initial_delay=0.5)

                if not response_data or not response_data.get('choices'):
                    logger.warning(f"Invalid AI response for university {university.get('name', '')}")
                    return None

                content = response_data['choices'][0]['message']['content']

                # Extract JSON
                start_idx = content.find('{')
                end_idx = content.rfind('}') + 1

                if start_idx == -1 or end_idx == 0:
                    logger.warning(f"Could not find JSON in filtering response for {university.get('name', '')}")
                    return None

                json_str = content[start_idx:end_idx]
                result = json.loads(json_str)

                matches = result.get('matches', False)
                reason = result.get('reason', '')

                logger.debug(f"Filtering result for {university.get('name', '')}: matches={matches}, reason={reason}")

                if matches:
                    return university
                return None

            except Exception as e:
                logger.warning(f"Failed to filter university {university.get('name', '')}: {str(e)}")
                # If filtering fails, include the university to avoid losing data
                return university

    # Execute filtering in parallel and emit results as they complete
    filtering_tasks = [_filter_single_university(uni) for uni in universities]
    
    # Process results as they complete for streaming
    filtered_universities = []
    completed_count = 0
    
    for coro in asyncio.as_completed(filtering_tasks):
        try:
            result = await coro
            completed_count += 1
            
            if result is not None:
                filtered_universities.append(result)
                # Emit progress for each completed filtering
                await _emit_progress("filtering", {
                    "current": completed_count, 
                    "total": len(universities),
                    "filtered_count": len(filtered_universities)
                })
                # Send individual university result if callback provided
                if university_callback is not None:
                    await university_callback(result)
        except Exception as e:
            logger.warning(f"Exception in filtering task: {e}")
            completed_count += 1
            # On exception, we can't determine which university, so skip progress update

    return filtered_universities

async def summarize_with_ai(search_results: List[dict], query: str):
    """
    Use Hugging Face model to summarize search results into structured university data
    """
    
    # Format search results as text
    results_text = ""
    for i, result in enumerate(search_results[:25], 1):  # Use up to first 25 results for broader coverage
        title = result.get("title", "No title")
        url = result.get("url", "No URL")
        content = result.get("content", "No content")
        # 500æ–‡å­—åˆ¶é™
        results_text += f"Result {i}:\nTitle: {title}\nURL: {url}\nContent: {content[:500]}...\n\n" 

    _debug_log(f"[summarize_with_ai] results_text length={len(results_text)} characters")

    # Create prompt for the model
    system_prompt = """ã‚ãªãŸã¯æ—¥æœ¬ã®å¤§å­¦å—é¨“ã«è©³ã—ã„ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
ä¸ãˆã‚‰ã‚ŒãŸæ¤œç´¢çµæœã‹ã‚‰æ­£ç¢ºãªæƒ…å ±ã‚’æŠ½å‡º
ã—ã€æŒ‡å®šã•ã‚ŒãŸJSONå½¢å¼ã§è¿”ã—ã¦ãã ã•ã„ã€‚
æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ã€æ¨æ¸¬ã›ãšã«ç©ºæ–‡å­—åˆ—ã‚„ç©ºé…åˆ—ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
å›ç­”ã«ã¯ã€JSONå½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ä»¥å¤–ã€ä½™åˆ†ãªãƒ†ã‚­ã‚¹ãƒˆã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚"""

    guidelines = dedent(
        """
        æ–¹é‡
        - åŒä¸€å¤§å­¦ã§ã‚‚ã€Œå­¦éƒ¨ãŒç•°ãªã‚‹ã€ã¾ãŸã¯ã€Œå…¥è©¦å½¢æ…‹ãŒç•°ãªã‚‹ã€å ´åˆã¯ã€åˆ¥ã®è¦ç´ ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼ˆå­¦éƒ¨ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³/æ–¹å¼ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å¯è¦–åŒ–ï¼‰ã€‚
        - æƒ…å ±æºã¯ PassNaviï¼ˆpassnavi.obunsha.co.jpï¼‰ã¨ Kei-Netï¼ˆkeinet.ne.jpï¼‰ã‚’å„ªå…ˆã—ã€å¯èƒ½ã§ã‚ã‚Œã° sources ã«ãã‚Œã‚‰ã®URLã‚’1ã¤ä»¥ä¸Šå«ã‚ã¦ãã ã•ã„ã€‚
        - å…¬å¼ã‚µã‚¤ãƒˆï¼ˆ*.ac.jpï¼‰ã®å…¥è©¦æƒ…å ±/è¦é …/admissionsãƒšãƒ¼ã‚¸ã‚‚ä¿¡é ¼ã§ãã¾ã™ã€‚sources ã«ã¯å¿…ãšå…¬å¼ã‚µã‚¤ãƒˆURLã‚’1ä»¶å«ã‚ã¦ãã ã•ã„ã€‚
        - sources ã«ã¯ä¿¡é ¼ã§ãã‚‹å…¥è©¦æƒ…å ±ã‚µã‚¤ãƒˆï¼ˆPassNavi: https://passnavi.obunsha.co.jp, Kei-Net: https://keinet.ne.jpï¼‰ã®URLã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„ã€‚ã“ã‚Œã‚‰ã®ã‚µã‚¤ãƒˆã‹ã‚‰ã®æƒ…å ±ãŒä½¿ç”¨ã•ã‚ŒãŸå ´åˆã¯ã€å¯¾å¿œã™ã‚‹URLã‚’sourcesã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚
        - ä¸æ˜ãªé …ç›®ã¯ç©ºæ–‡å­—åˆ—ã‚„ç©ºé…åˆ—ã®ã¾ã¾ã«ã—ã¦ãã ã•ã„ï¼ˆæ¨æ¸¬ç¦æ­¢ï¼‰ã€‚
        - "deviationScore"ï¼ˆåå·®å€¤ï¼‰ã¯ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºï¼ˆPassNaviã€Kei-Netã€å…¬å¼ã‚µã‚¤ãƒˆï¼‰ã‹ã‚‰ã®æƒ…å ±ã®ã¿ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚ä¿¡é ¼ã§ããªã„ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®åå·®å€¤ã¯è¨˜è¼‰ã—ãªã„ã§ãã ã•ã„ã€‚
        - "aiSummary" ã«ã¯ã€è¤‡æ•°ã®æƒ…å ±æºã‹ã‚‰å¾—ã‚‰ã‚ŒãŸå…·ä½“çš„ãªäº‹å®Ÿã‚’æœ€ä½ã§ã‚‚2ã¤å«ã‚ã¦ãã ã•ã„ã€‚ï¼ˆä¾‹: å­¦éƒ¨ã®ç‰¹è‰² + å…¥è©¦æ–¹å¼/é…ç‚¹ + ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹ã®ç‰¹å¾´ï¼‰ã€‚å˜ãªã‚‹ç¹°ã‚Šè¿”ã—ã‚„æ›–æ˜§ãªè¡¨ç¾ã¯é¿ã‘ã€å®Ÿéš›ã®æ¤œç´¢çµæœã‹ã‚‰å¾—ã‚‰ã‚ŒãŸå†…å®¹ã‚’ç°¡æ½”ã«çµ±åˆã—ã¦ãã ã•ã„ã€‚
        - "examSchedules" ã«ã¯ã€Œé¡˜æ›¸å—ä»˜ã€ã€Œå‡ºé¡˜ç· åˆ‡ã€ã€Œè©¦é¨“æ—¥ã€ã€Œåˆæ ¼ç™ºè¡¨ã€ãªã©ã®æ—¥ç¨‹ã‚’æ™‚ç³»åˆ—ã§åˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚
        - "admissionMethods" ã«ã¯ "ä¸€èˆ¬é¸æŠœ" ã‚„ "ç·åˆå‹é¸æŠœ" ãªã©ã®æ–¹å¼åã‚’åˆ—æŒ™ã—ã€å¿…è¦ã§ã‚ã‚Œã°é…ç‚¹ã‚„ç‰¹å¾´ã‚’ä½µè¨˜ã—ã¦ãã ã•ã„ã€‚
        - "subjectHighlights" ã«ã¯å„ç§‘ç›®ã®é…ç‚¹æ¯”ç‡ã‚„å¿…é ˆ/é¸æŠåŒºåˆ†ãªã©ã®å…¥è©¦ã«ç‰¹åŒ–ã—ãŸæƒ…å ±ã‚’åˆ—æŒ™ã—ã¦ãã ã•ã„ã€‚
        - "commonTestRatio" ãŒåˆ¤æ˜ã—ã¦ã„ã‚‹å ´åˆã¯ç™¾åˆ†ç‡ã‚„ã€Œâ—‹å‰²ã€ã¨ã„ã£ãŸå½¢å¼ã§è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
        - "selectionNotes" ã«ã¯ç‰¹è¨˜äº‹é …ï¼ˆå†å—é¨“å¯å¦ã€é¢æ¥ã®æœ‰ç„¡ã€å‡ºé¡˜æ¡ä»¶ãªã©ï¼‰ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
        - "applicationDeadline" ã«ã¯é¡˜æ›¸æå‡ºã®ç· åˆ‡æ—¥ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚
        - "institutionType" ã«ã¯å¤§å­¦ã®ç¨®é¡ï¼ˆå›½ç«‹/å…¬ç«‹/ç§ç«‹ï¼‰ã‚’å¿…ãšè¨˜è¼‰ã—ã¦ãã ã•ã„ã€‚å…¬å¼ã‚µã‚¤ãƒˆã®ãƒ‰ãƒ¡ã‚¤ãƒ³ï¼ˆ*.ac.jpï¼‰ã‹ã‚‰åˆ¤æ–­ã—ã€å›½ç«‹å¤§å­¦ã¯ã€Œå›½ç«‹ã€ã€å…¬ç«‹å¤§å­¦ã¯ã€Œå…¬ç«‹ã€ã€ãã‚Œä»¥å¤–ã¯ã€Œç§ç«‹ã€ã¨è¨­å®šã—ã¦ãã ã•ã„ã€‚
        """
    ).strip()

    user_prompt = dedent(
        f"""ä»¥ä¸‹ã®æ¤œç´¢çµæœã‹ã‚‰ã€å¤§å­¦æƒ…å ±ã‚’æŠ½å‡ºã—ã¦æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ã€‚

æ¤œç´¢ã‚¯ã‚¨ãƒª: {query}

æ¤œç´¢çµæœ:
{results_text}

{guidelines}

ä»¥ä¸‹ã®JSONå½¢å¼ã§ã€è¦‹ã¤ã‹ã£ãŸå¤§å­¦æƒ…å ±ã‚’é…åˆ—ã§è¿”ã—ã¦ãã ã•ã„ï¼ˆæœ€å¤§20ä»¶ï¼‰ã€‚ç•°ãªã‚‹å¤§å­¦ã‚’å„ªå…ˆã—ã¤ã¤ã€åŒä¸€å¤§å­¦å†…ã®å­¦éƒ¨/å…¥è©¦å½¢æ…‹ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚‚å«ã‚ã€é‡è¤‡ã¯é¿ã‘ã¦ãã ã•ã„ã€‚

å‡ºåŠ›ã¯JSONé…åˆ—ã®ã¿ã¨ã—ã€ãã‚Œä»¥å¤–ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸€åˆ‡å«ã‚ãªã„ã§ãã ã•ã„ã€‚JSONã®å‰ã«èª¬æ˜æ–‡ã‚„```jsonã¯ä¸è¦ã§ã™ã€‚ç›´æ¥[ã§å§‹ã¾ã‚‹JSONé…åˆ—ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚"""
    ).strip()

    user_prompt = f"{user_prompt}\n\n{JSON_OUTPUT_EXAMPLE}"

    _debug_log("[summarize_with_ai] constructed user prompt for Hugging Face model")

    # Hugging Faceã®Chat Completions APIã«æ¸¡ã™ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]

    try:
        logger.debug("Calling Hugging Face Chat API for summarization...")
        _debug_log("[summarize_with_ai] requesting Hugging Face completion")
        
        # å‘¼ã³å‡ºã—é–¢æ•°ã‚’query_hf_inferenceã«å¤‰æ›´
        response_data = await query_hf_inference(messages)
        
        # Extract the generated text from the response
        if not response_data or not response_data.get('choices'):
            raise ValueError("Invalid response format from Hugging Face API")
            
        content = response_data['choices'][0]['message']['content']
        
        # Clean up the response - extract just the JSON part
        start_idx = content.find('[')
        end_idx = content.rfind(']') + 1
        
        # ... (JSONãƒ‘ãƒ¼ã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã¯å¤‰æ›´ãªã—)
        if start_idx == -1 or end_idx == 0:
            # ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã£ã¦ã¯ã€JSONã®å‰ã«èª¬æ˜æ–‡ã‚’è¿½åŠ ã™ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€æŸ”è»Ÿã«å‡¦ç†
            logger.warning("Could not find JSON array in response. Attempting to clean...")
            # ã‚‚ã—JSONã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦è¿”ã•ã‚ŒãŸå ´åˆï¼ˆä¾‹: ```json[...]```ï¼‰
            if content.strip().startswith('```') and content.strip().endswith('```'):
                content = content.strip()[content.strip().find('\n')+1 : content.strip().rfind('```')].strip()
                start_idx = content.find('[')
                end_idx = content.rfind(']') + 1
                if start_idx != -1 and end_idx != 0:
                    json_str = content[start_idx:end_idx]
                else:
                    # Try to find any JSON-like structure
                    import re
                    json_match = re.search(r'\[.*\]', content, re.DOTALL)
                    if json_match:
                        json_str = json_match.group()
                    else:
                        raise ValueError("Could not find JSON array in response even after code block cleaning")
            else:
                # Try to find any JSON-like structure
                import re
                json_match = re.search(r'\[.*\]', content, re.DOTALL)
                if json_match:
                    json_str = json_match.group()
                else:
                    raise ValueError("Could not find JSON array in response")

        else:
            json_str = content[start_idx:end_idx]
        
        logger.debug(f"Raw AI response: {json_str}")
        
        # Parse the JSON
        universities = json.loads(json_str)
        if not isinstance(universities, list):
            universities = [universities]
            
        logger.info(f"AI summarization successful, extracted {len(universities)} universities")
        _debug_log(f"[summarize_with_ai] extracted {len(universities)} universities from response")
        return universities
        
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse AI response as JSON: {str(e)}")
        logger.debug(f"Problematic content: {content if 'content' in locals() else 'N/A'}")
        _debug_log(f"[summarize_with_ai] JSON decode error: {str(e)}")
    except Exception as e:
        logger.error(f"AI summarization failed: {str(e)}")
        _debug_log(f"[summarize_with_ai] summarization exception: {str(e)}")
        
    # Fall back to mock data if anything goes wrong
    return generate_mock_universities()


# generate_mock_universities é–¢æ•°ã¯å¤‰æ›´ãªã—

def generate_mock_universities() -> List[dict]:
    # ... (ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆé–¢æ•°ã¯å¤‰æ›´ãªã—)
    """
    Generate mock university data for testing
    """
    return [
        {
            "id": "1",
            "name": "æ±äº¬å¤§å­¦",
            "officialUrl": "https://www.u-tokyo.ac.jp/",
            "faculty": "å·¥å­¦éƒ¨",
            "department": "æƒ…å ±å·¥å­¦ç§‘",
            "deviationScore": "70-75",
            "commonTestScore": "90-95%",
            "examType": "ä¸€èˆ¬é¸æŠœ",
            "requiredSubjects": ["æ•°å­¦", "ç†ç§‘", "è‹±èª"],
            "examDate": "2025å¹´2æœˆ25æ—¥",
            "examSchedules": [
                "é¡˜æ›¸å—ä»˜: 2024å¹´12æœˆ1æ—¥",
                "å‡ºé¡˜ç· åˆ‡: 2025å¹´1æœˆ15æ—¥",
                "è©¦é¨“æ—¥: 2025å¹´2æœˆ25æ—¥",
                "åˆæ ¼ç™ºè¡¨: 2025å¹´3æœˆ10æ—¥",
            ],
            "admissionMethods": ["ä¸€èˆ¬é¸æŠœ: å‰æœŸæ—¥ç¨‹ 3æ•™ç§‘å‹", "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹: æ•°å­¦ãƒ»è‹±èªé‡è¦–"],
            "subjectHighlights": ["æ•°å­¦: 200ç‚¹", "ç†ç§‘: 150ç‚¹ (ç‰©ç†/åŒ–å­¦)", "è‹±èª: 150ç‚¹"],
            "commonTestRatio": "å…±é€šãƒ†ã‚¹ãƒˆ60% / å€‹åˆ¥è©¦é¨“40%",
            "selectionNotes": "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹ã¯è‹±èªå¤–éƒ¨æ¤œå®šã‚’æ›ç®—å¯",
            "applicationDeadline": "2025å¹´1æœˆ15æ—¥",
            "aiSummary": "æ—¥æœ¬æœ€é«˜å³°ã®ç ”ç©¶ç’°å¢ƒã€‚ä¸–ç•Œçš„ãªç ”ç©¶è€…ãŒå¤šæ•°åœ¨ç±ã—ã€æœ€å…ˆç«¯ã®æ•™è‚²ã‚’å—ã‘ã‚‰ã‚Œã‚‹ã€‚",
            "sources": ["https://www.u-tokyo.ac.jp/"]
        },
        {
            "id": "2",
            "name": "äº¬éƒ½å¤§å­¦",
            "officialUrl": "https://www.kyoto-u.ac.jp/",
            "faculty": "å·¥å­¦éƒ¨",
            "department": "æƒ…å ±å­¦ç§‘",
            "deviationScore": "68-73",
            "commonTestScore": "88-93%",
            "examType": "ä¸€èˆ¬é¸æŠœ",
            "requiredSubjects": ["æ•°å­¦", "ç†ç§‘", "è‹±èª"],
            "examDate": "2025å¹´2æœˆ25æ—¥",
            "examSchedules": [
                "é¡˜æ›¸å—ä»˜: 2024å¹´12æœˆ10æ—¥",
                "å‡ºé¡˜ç· åˆ‡: 2025å¹´1æœˆ20æ—¥",
                "è©¦é¨“æ—¥: 2025å¹´2æœˆ25æ—¥",
            ],
            "admissionMethods": ["ä¸€èˆ¬é¸æŠœ: å‰æœŸæ—¥ç¨‹", "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹: 5æ•™ç§‘7ç§‘ç›®"],
            "subjectHighlights": ["æ•°å­¦: 200ç‚¹", "ç†ç§‘: 200ç‚¹", "è‹±èª: 150ç‚¹"],
            "commonTestRatio": "å…±é€šãƒ†ã‚¹ãƒˆ70% / å€‹åˆ¥è©¦é¨“30%",
            "selectionNotes": "ç¬¬äºŒæ®µéšé¸æŠœã§é¢æ¥ã‚ã‚Š",
            "applicationDeadline": "2025å¹´1æœˆ20æ—¥",
            "aiSummary": "è‡ªç”±ãªå­¦é¢¨ã¨é«˜ã„ç ”ç©¶åŠ›ã€‚ãƒãƒ¼ãƒ™ãƒ«è³å—è³è€…ã‚‚å¤šæ•°è¼©å‡ºã—ã¦ã„ã‚‹åé–€å¤§å­¦ã€‚",
            "sources": ["https://www.kyoto-u.ac.jp/"]
        },
        {
            "id": "3",
            "name": "å¤§é˜ªå¤§å­¦",
            "officialUrl": "https://www.osaka-u.ac.jp/",
            "faculty": "åŸºç¤å·¥å­¦éƒ¨",
            "department": "æƒ…å ±ç§‘å­¦ç§‘",
            "deviationScore": "65-70",
            "commonTestScore": "85-90%",
            "examType": "ä¸€èˆ¬é¸æŠœ",
            "requiredSubjects": ["æ•°å­¦", "ç†ç§‘", "è‹±èª"],
            "examDate": "2025å¹´2æœˆ24æ—¥",
            "examSchedules": [
                "é¡˜æ›¸å—ä»˜: 2024å¹´12æœˆ5æ—¥",
                "å‡ºé¡˜ç· åˆ‡: 2025å¹´1æœˆ18æ—¥",
                "è©¦é¨“æ—¥: 2025å¹´2æœˆ24æ—¥",
            ],
            "admissionMethods": ["ä¸€èˆ¬é¸æŠœ: å‰æœŸ/å¾ŒæœŸ", "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹: 5æ•™ç§‘"],
            "subjectHighlights": ["æ•°å­¦: 180ç‚¹", "ç†ç§‘: 180ç‚¹", "è‹±èª: 140ç‚¹"],
            "commonTestRatio": "å…±é€šãƒ†ã‚¹ãƒˆ55% / å€‹åˆ¥è©¦é¨“45%",
            "selectionNotes": "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹ã¯å‡ºé¡˜è³‡æ ¼ã«å¤–éƒ¨è‹±èªè©¦é¨“ä¸è¦",
            "applicationDeadline": "2025å¹´1æœˆ18æ—¥",
            "aiSummary": "æƒ…å ±ç§‘å­¦åˆ†é‡ã§å›½å†…æœ‰æ•°ã®ç ”ç©¶ç’°å¢ƒã¨ä¼æ¥­é€£æºã‚’æœ‰ã™ã‚‹ã€‚",
            "sources": ["https://www.osaka-u.ac.jp/"],
            "institutionType": "å›½ç«‹",
        },
        {
            "id": "4",
            "name": "æ±åŒ—å¤§å­¦",
            "officialUrl": "https://www.tohoku.ac.jp/",
            "faculty": "å·¥å­¦éƒ¨",
            "department": "æƒ…å ±çŸ¥èƒ½ã‚·ã‚¹ãƒ†ãƒ ç·åˆå­¦ç§‘",
            "deviationScore": "62-67",
            "commonTestScore": "82-88%",
            "examType": "ä¸€èˆ¬é¸æŠœ",
            "requiredSubjects": ["æ•°å­¦", "ç†ç§‘", "è‹±èª"],
            "examDate": "2025å¹´2æœˆ26æ—¥",
            "examSchedules": [
                "é¡˜æ›¸å—ä»˜: 2024å¹´12æœˆ8æ—¥",
                "å‡ºé¡˜ç· åˆ‡: 2025å¹´1æœˆ21æ—¥",
                "è©¦é¨“æ—¥: 2025å¹´2æœˆ26æ—¥",
            ],
            "admissionMethods": ["ä¸€èˆ¬é¸æŠœ: å‰æœŸ", "AOå…¥è©¦: ç·åˆå‹é¸æŠœ"],
            "subjectHighlights": ["æ•°å­¦: 150ç‚¹", "ç†ç§‘: 150ç‚¹", "è‹±èª: 120ç‚¹"],
            "commonTestRatio": "å…±é€šãƒ†ã‚¹ãƒˆ50% / å€‹åˆ¥è©¦é¨“50%",
            "selectionNotes": "AOå…¥è©¦ã¯å¿—æœ›ç†ç”±æ›¸æå‡ºãŒå¿…è¦",
            "applicationDeadline": "2025å¹´1æœˆ21æ—¥",
            "aiSummary": "å®Ÿå­¦é‡è¦–ã®ç ”ç©¶ã§è©•ä¾¡ãŒé«˜ã„ã€‚AIãƒ»ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹åˆ†é‡ã‚‚å……å®Ÿã€‚",
            "sources": ["https://www.tohoku.ac.jp/"],
            "institutionType": "å›½ç«‹",
        },
        {
            "id": "5",
            "name": "æ—©ç¨²ç”°å¤§å­¦",
            "officialUrl": "https://www.waseda.jp/",
            "faculty": "åŸºå¹¹ç†å·¥å­¦éƒ¨",
            "department": "æƒ…å ±ç†å·¥å­¦ç§‘",
            "deviationScore": "60-65",
            "commonTestScore": "80-85%",
            "examType": "ä¸€èˆ¬é¸æŠœ",
            "requiredSubjects": ["æ•°å­¦", "ç†ç§‘", "è‹±èª"],
            "examDate": "2025å¹´2æœˆ20æ—¥",
            "examSchedules": [
                "é¡˜æ›¸å—ä»˜: 2024å¹´12æœˆ15æ—¥",
                "å‡ºé¡˜ç· åˆ‡: 2025å¹´1æœˆ25æ—¥",
                "è©¦é¨“æ—¥: 2025å¹´2æœˆ20æ—¥",
            ],
            "admissionMethods": ["ä¸€èˆ¬é¸æŠœ: 3æ•™ç§‘å‹", "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹: ãƒœãƒ¼ãƒ€ãƒ¼ãƒ•ãƒªãƒ¼æ–¹å¼"],
            "subjectHighlights": ["æ•°å­¦: 150ç‚¹", "è‹±èª: 150ç‚¹", "ç†ç§‘: 150ç‚¹"],
            "commonTestRatio": "å…±é€šãƒ†ã‚¹ãƒˆ40% / å€‹åˆ¥è©¦é¨“60%",
            "selectionNotes": "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹ã¯ãƒœãƒ¼ãƒ€ãƒ¼ãƒ•ãƒªãƒ¼æ–¹å¼ã‚ã‚Š",
            "applicationDeadline": "2025å¹´1æœˆ25æ—¥",
            "aiSummary": "ç§å­¦ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®ç†å·¥ç³»ã€‚å¹…åºƒã„åˆ†é‡ã¨å›½éš›é€£æºãŒé­…åŠ›ã€‚",
            "sources": ["https://www.waseda.jp/"],
            "institutionType": "ç§ç«‹",
        },
        {
            "id": "6",
            "name": "æ…¶æ‡‰ç¾©å¡¾å¤§å­¦",
            "officialUrl": "https://www.keio.ac.jp/",
            "faculty": "ç†å·¥å­¦éƒ¨",
            "department": "æƒ…å ±å·¥å­¦ç§‘",
            "deviationScore": "62-67",
            "commonTestScore": "82-87%",
            "examType": "ä¸€èˆ¬é¸æŠœ",
            "requiredSubjects": ["æ•°å­¦", "ç†ç§‘", "è‹±èª"],
            "examDate": "2025å¹´2æœˆ18æ—¥",
            "examSchedules": [
                "é¡˜æ›¸å—ä»˜: 2024å¹´12æœˆ12æ—¥",
                "å‡ºé¡˜ç· åˆ‡: 2025å¹´1æœˆ22æ—¥",
                "è©¦é¨“æ—¥: 2025å¹´2æœˆ18æ—¥",
            ],
            "admissionMethods": ["ä¸€èˆ¬é¸æŠœ: å‰æœŸãƒ»å¾ŒæœŸ", "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹: é«˜å¾—ç‚¹ç§‘ç›®é‡è¦–"],
            "subjectHighlights": ["æ•°å­¦: 180ç‚¹", "è‹±èª: 180ç‚¹", "ç†ç§‘: 140ç‚¹"],
            "commonTestRatio": "å…±é€šãƒ†ã‚¹ãƒˆ50% / å€‹åˆ¥è©¦é¨“50%",
            "selectionNotes": "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹ã¯è‹±èªå¤–éƒ¨è©¦é¨“åŠ ç‚¹ã‚ã‚Š",
            "applicationDeadline": "2025å¹´1æœˆ22æ—¥",
            "aiSummary": "ç”£æ¥­ç•Œã¨ã®çµã³ã¤ããŒå¼·ãå®Ÿè·µçš„ã€‚ç ”ç©¶ç’°å¢ƒã¨å°±è·ã«å¼·ã¿ã€‚",
            "sources": ["https://www.keio.ac.jp/"],
            "institutionType": "ç§ç«‹",
        },
        {
            "id": "1",
            "name": "æ±äº¬å·¥æ¥­å¤§å­¦",
            "officialUrl": "https://www.titech.ac.jp/",
            "faculty": "æƒ…å ±ç†å·¥å­¦é™¢",
            "department": "æƒ…å ±å·¥å­¦ç³»",
            "deviationScore": "65-70",
            "commonTestScore": "85-90%",
            "examType": "ä¸€èˆ¬é¸æŠœ",
            "requiredSubjects": ["æ•°å­¦", "ç†ç§‘", "è‹±èª"],
            "examDate": "2025å¹´2æœˆ25æ—¥",
            "examSchedules": [
                "é¡˜æ›¸å—ä»˜: 2024å¹´12æœˆ1æ—¥",
                "å‡ºé¡˜ç· åˆ‡: 2025å¹´1æœˆ15æ—¥",
                "è©¦é¨“æ—¥: 2025å¹´2æœˆ25æ—¥",
                "åˆæ ¼ç™ºè¡¨: 2025å¹´3æœˆ10æ—¥",
            ],
            "admissionMethods": ["ä¸€èˆ¬é¸æŠœ: å‰æœŸæ—¥ç¨‹ 3æ•™ç§‘å‹", "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹: æ•°å­¦ãƒ»è‹±èªé‡è¦–"],
            "subjectHighlights": ["æ•°å­¦: 200ç‚¹", "ç†ç§‘: 150ç‚¹", "è‹±èª: 150ç‚¹"],
            "commonTestRatio": "å…±é€šãƒ†ã‚¹ãƒˆ60% / å€‹åˆ¥è©¦é¨“40%",
            "selectionNotes": "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹ã¯è‹±èªå¤–éƒ¨æ¤œå®šã‚’æ›ç®—å¯",
            "applicationDeadline": "2025å¹´1æœˆ15æ—¥",
            "institutionType": "å›½ç«‹",
            "aiSummary": "æƒ…å ±å·¥å­¦åˆ†é‡ã§æ—¥æœ¬ãƒˆãƒƒãƒ—ã‚¯ãƒ©ã‚¹ã®ç ”ç©¶ç’°å¢ƒã‚’èª‡ã‚‹ã€‚AIãƒ»æ©Ÿæ¢°å­¦ç¿’ã®ç ”ç©¶ãŒç››ã‚“ã§ã€ç”£å­¦é€£æºã‚‚å……å®Ÿã€‚",
            "sources": ["https://www.titech.ac.jp/", "https://admissions.titech.ac.jp/"],
        },
        {
            "id": "2",
            "name": "æ—©ç¨²ç”°å¤§å­¦",
            "officialUrl": "https://www.waseda.jp/",
            "faculty": "åŸºå¹¹ç†å·¥å­¦éƒ¨",
            "department": "æƒ…å ±ç†å·¥å­¦ç§‘",
            "deviationScore": "60-65",
            "commonTestScore": "80-85%",
            "examType": "ä¸€èˆ¬é¸æŠœ",
            "requiredSubjects": ["æ•°å­¦", "ç†ç§‘", "è‹±èª"],
            "examDate": "2025å¹´2æœˆ20æ—¥",
            "examSchedules": [
                "é¡˜æ›¸å—ä»˜: 2024å¹´12æœˆ15æ—¥",
                "å‡ºé¡˜ç· åˆ‡: 2025å¹´1æœˆ25æ—¥",
                "è©¦é¨“æ—¥: 2025å¹´2æœˆ20æ—¥",
            ],
            "admissionMethods": ["ä¸€èˆ¬é¸æŠœ: 3æ•™ç§‘å‹", "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹: ãƒœãƒ¼ãƒ€ãƒ¼ãƒ•ãƒªãƒ¼æ–¹å¼"],
            "subjectHighlights": ["æ•°å­¦: 150ç‚¹", "è‹±èª: 150ç‚¹", "ç†ç§‘: 150ç‚¹"],
            "commonTestRatio": "å…±é€šãƒ†ã‚¹ãƒˆ40% / å€‹åˆ¥è©¦é¨“60%",
            "selectionNotes": "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹ã¯ãƒœãƒ¼ãƒ€ãƒ¼ãƒ•ãƒªãƒ¼æ–¹å¼ã‚ã‚Š",
            "applicationDeadline": "2025å¹´1æœˆ25æ—¥",
            "institutionType": "ç§ç«‹",
            "aiSummary": "ä¼çµ±ã‚ã‚‹ç§ç«‹å¤§å­¦ã®ç†å·¥å­¦éƒ¨ã€‚å¹…åºƒã„åˆ†é‡ã®ç ”ç©¶ãŒå¯èƒ½ã§ã€å°±è·å®Ÿç¸¾ã‚‚è‰¯å¥½ã€‚å›½éš›äº¤æµãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚‚å……å®Ÿã€‚",
            "sources": ["https://www.waseda.jp/"],
        },
        {
            "id": "3",
            "name": "æ…¶æ‡‰ç¾©å¡¾å¤§å­¦",
            "officialUrl": "https://www.keio.ac.jp/",
            "faculty": "ç†å·¥å­¦éƒ¨",
            "department": "æƒ…å ±å·¥å­¦ç§‘",
            "deviationScore": "62-67",
            "commonTestScore": "82-87%",
            "examType": "ä¸€èˆ¬é¸æŠœ",
            "requiredSubjects": ["æ•°å­¦", "ç†ç§‘", "è‹±èª"],
            "examDate": "2025å¹´2æœˆ18æ—¥",
            "examSchedules": [
                "é¡˜æ›¸å—ä»˜: 2024å¹´12æœˆ12æ—¥",
                "å‡ºé¡˜ç· åˆ‡: 2025å¹´1æœˆ22æ—¥",
                "è©¦é¨“æ—¥: 2025å¹´2æœˆ18æ—¥",
            ],
            "admissionMethods": ["ä¸€èˆ¬é¸æŠœ: å‰æœŸãƒ»å¾ŒæœŸ", "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹: é«˜å¾—ç‚¹ç§‘ç›®é‡è¦–"],
            "subjectHighlights": ["æ•°å­¦: 180ç‚¹", "è‹±èª: 180ç‚¹", "ç†ç§‘: 140ç‚¹"],
            "commonTestRatio": "å…±é€šãƒ†ã‚¹ãƒˆ50% / å€‹åˆ¥è©¦é¨“50%",
            "selectionNotes": "å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨å‹ã¯è‹±èªå¤–éƒ¨è©¦é¨“åŠ ç‚¹ã‚ã‚Š",
            "applicationDeadline": "2025å¹´1æœˆ22æ—¥",
            "institutionType": "ç§ç«‹",
            "aiSummary": "ç·åˆåŠ›ã®é«˜ã„ç†å·¥å­¦éƒ¨ã€‚ç”£æ¥­ç•Œã¨ã®ã¤ãªãŒã‚ŠãŒå¼·ãã€å®Ÿè·µçš„ãªæ•™è‚²ãŒç‰¹å¾´ã€‚ã‚­ãƒ£ãƒ³ãƒ‘ã‚¹ç’°å¢ƒã‚‚å„ªã‚Œã¦ã„ã‚‹ã€‚",
            "sources": ["https://www.keio.ac.jp/"],
        },
    ]


# Regional university mappings for broader coverage
REGIONAL_UNIVERSITIES = {
    "åŒ—æµ·é“": [
        "åŒ—æµ·é“å¤§å­¦", "åŒ—æµ·é“æ•™è‚²å¤§å­¦", "å®¤è˜­å·¥æ¥­å¤§å­¦", "å°æ¨½å•†ç§‘å¤§å­¦", "å¸¯åºƒç•œç”£å¤§å­¦",
        "åŒ—è¦‹å·¥æ¥­å¤§å­¦", "æ—­å·åŒ»ç§‘å¤§å­¦", "æœ­å¹ŒåŒ»ç§‘å¤§å­¦", "æœ­å¹Œå¸‚ç«‹å¤§å­¦", "åŒ—æµ·é“ç§‘å­¦å¤§å­¦"
    ],
    "æ±åŒ—": [
        "æ±åŒ—å¤§å­¦", "å¼˜å‰å¤§å­¦", "å²©æ‰‹å¤§å­¦", "ç§‹ç”°å¤§å­¦", "å±±å½¢å¤§å­¦", "ç¦å³¶å¤§å­¦",
        "å®®åŸæ•™è‚²å¤§å­¦", "æ±åŒ—å·¥æ¥­å¤§å­¦", "æ±åŒ—å­¦é™¢å¤§å­¦", "ä»™å°ç™½ç™¾åˆå¥³å­å¤§å­¦"
    ],
    "é–¢æ±": [
        "æ±äº¬å¤§å­¦", "æ±äº¬å·¥æ¥­å¤§å­¦", "ä¸€æ©‹å¤§å­¦", "æ±äº¬åŒ»ç§‘æ­¯ç§‘å¤§å­¦", "æ±äº¬å¤–å›½èªå¤§å­¦",
        "æ±äº¬è¾²å·¥å¤§å­¦", "é›»æ°—é€šä¿¡å¤§å­¦", "æ±äº¬æµ·æ´‹å¤§å­¦", "æ±äº¬èŠ¸è¡“å¤§å­¦", "æ”¿ç­–ç ”ç©¶å¤§å­¦é™¢å¤§å­¦",
        "æ—©ç¨²ç”°å¤§å­¦", "æ…¶æ‡‰ç¾©å¡¾å¤§å­¦", "æ˜æ²»å¤§å­¦", "ç«‹æ•™å¤§å­¦", "ä¸­å¤®å¤§å­¦", "æ³•æ”¿å¤§å­¦",
        "æ±äº¬ç†ç§‘å¤§å­¦", "é’å±±å­¦é™¢å¤§å­¦", "å­¦ç¿’é™¢å¤§å­¦", "æ˜æ²»å­¦é™¢å¤§å­¦", "ç¨å”å¤§å­¦",
        "æˆåŸå¤§å­¦", "æˆè¹Šå¤§å­¦", "æ—¥æœ¬å¤§å­¦", "æ±æ´‹å¤§å­¦", "é§’æ¾¤å¤§å­¦", "å°‚ä¿®å¤§å­¦",
        "åœ‹å­¸é™¢å¤§å­¸", "å¤§æ±æ–‡åŒ–å¤§å­¦", "äºœç´°äºœå¤§å­¦", "æ±äº¬çµŒæ¸ˆå¤§å­¦", "æ­¦è”µå¤§å­¦",
        "æ±äº¬éƒ½å¸‚å¤§å­¦", "æ±äº¬é›»æ©Ÿå¤§å­¦", "å·¥å­¦é™¢å¤§å­¦", "èŠæµ¦å·¥æ¥­å¤§å­¦", "æ—¥æœ¬å·¥æ¥­å¤§å­¦"
    ],
    "ä¸­éƒ¨": [
        "åå¤å±‹å¤§å­¦", "å²é˜œå¤§å­¦", "é™å²¡å¤§å­¦", "æ„›çŸ¥æ•™è‚²å¤§å­¦", "è±Šæ©‹æŠ€è¡“ç§‘å­¦å¤§å­¦",
        "åå¤å±‹å·¥æ¥­å¤§å­¦", "è±Šç”°å·¥æ¥­å¤§å­¦", "åå¤å±‹å¸‚ç«‹å¤§å­¦", "é‡‘æ²¢å¤§å­¦", "å¯Œå±±å¤§å­¦",
        "ç¦äº•å¤§å­¦", "æ–°æ½Ÿå¤§å­¦", "é•·å²¡æŠ€è¡“ç§‘å­¦å¤§å­¦", "å±±æ¢¨å¤§å­¦", "ä¿¡å·å¤§å­¦",
        "åå¤å±‹å¤–å›½èªå¤§å­¦", "ä¸­äº¬å¤§å­¦", "å—å±±å¤§å­¦", "ååŸå¤§å­¦", "æ„›çŸ¥å¤§å­¦",
        "æ„›çŸ¥å·¥æ¥­å¤§å­¦", "æ„›çŸ¥å­¦é™¢å¤§å­¦", "è±Šç”°å·¥æ¥­å¤§å­¦", "æ—¥æœ¬ç¦ç¥‰å¤§å­¦"
    ],
    "è¿‘ç•¿": [
        "äº¬éƒ½å¤§å­¦", "å¤§é˜ªå¤§å­¦", "ç¥æˆ¸å¤§å­¦", "å¤§é˜ªå¸‚ç«‹å¤§å­¦", "å¤§é˜ªåºœç«‹å¤§å­¦",
        "å…µåº«çœŒç«‹å¤§å­¦", "å¥ˆè‰¯å¥³å­å¤§å­¦", "æ»‹è³€å¤§å­¦", "å’Œæ­Œå±±å¤§å­¦", "äº¬éƒ½åºœç«‹å¤§å­¦",
        "äº¬éƒ½å·¥èŠ¸ç¹Šç¶­å¤§å­¦", "äº¬éƒ½æ•™è‚²å¤§å­¦", "å¤§é˜ªæ•™è‚²å¤§å­¦", "é–¢è¥¿å¤§å­¦", "é–¢è¥¿å­¦é™¢å¤§å­¦",
        "åŒå¿—ç¤¾å¤§å­¦", "ç«‹å‘½é¤¨å¤§å­¦", "é¾è°·å¤§å­¦", "ä½›æ•™å¤§å­¦", "äº¬éƒ½ç”£æ¥­å¤§å­¦",
        "è¿‘ç•¿å¤§å­¦", "å¤§é˜ªå·¥æ¥­å¤§å­¦", "å¤§é˜ªé›»æ°—é€šä¿¡å¤§å­¦", "æ‘‚å—å¤§å­¦", "ç”²å—å¤§å­¦",
        "ç¥æˆ¸å­¦é™¢å¤§å­¦", "å¤§æ‰‹å‰å¤§å­¦", "æ¡ƒå±±å­¦é™¢å¤§å­¦", "è¿½æ‰‹é–€å­¦é™¢å¤§å­¦"
    ],
    "ä¸­å›½": [
        "åºƒå³¶å¤§å­¦", "å²¡å±±å¤§å­¦", "é³¥å–å¤§å­¦", "å³¶æ ¹å¤§å­¦", "å±±å£å¤§å­¦",
        "åºƒå³¶å¸‚ç«‹å¤§å­¦", "å°¾é“å¸‚ç«‹å¤§å­¦", "å²¡å±±çœŒç«‹å¤§å­¦", "åºƒå³¶ä¿®é“å¤§å­¦",
        "åºƒå³¶çµŒæ¸ˆå¤§å­¦", "å®‰ç”°å¥³å­å¤§å­¦", "ç¦å±±å¤§å­¦", "å±±é™½å¥³å­çŸ­æœŸå¤§å­¦"
    ],
    "å››å›½": [
        "å¾³å³¶å¤§å­¦", "é¦™å·å¤§å­¦", "æ„›åª›å¤§å­¦", "é«˜çŸ¥å¤§å­¦", "é³´é–€æ•™è‚²å¤§å­¦",
        "å››å›½å¤§å­¦", "æ¾å±±å¤§å­¦", "é«˜çŸ¥å·¥ç§‘å¤§å­¦", "å¾³å³¶æ–‡ç†å¤§å­¦"
    ],
    "ä¹å·": [
        "ä¹å·å¤§å­¦", "åŒ—ä¹å·å¤§å­¦", "ç†Šæœ¬å¤§å­¦", "é¹¿å…å³¶å¤§å­¦", "é•·å´å¤§å­¦",
        "å¤§åˆ†å¤§å­¦", "ä½è³€å¤§å­¦", "ç‰çƒå¤§å­¦", "å®®å´å¤§å­¦", "é¹¿å±‹ä½“è‚²å¤§å­¦",
        "ä¹å·å·¥æ¥­å¤§å­¦", "ç¦å²¡å¤§å­¦", "è¥¿å—å­¦é™¢å¤§å­¦", "ä¹å·ç”£æ¥­å¤§å­¦",
        "ä¹…ç•™ç±³å¤§å­¦", "é•·å´å›½éš›å¤§å­¦", "ç†Šæœ¬çœŒç«‹å¤§å­¦", "å®®å´ç”£æ¥­çµŒå–¶å¤§å­¦"
    ],
    "æ²–ç¸„": [
        "ç‰çƒå¤§å­¦", "æ²–ç¸„å›½éš›å¤§å­¦", "æ²–ç¸„å¤§å­¦", "åæ¡œå¤§å­¦", "æ²–ç¸„ã‚­ãƒªã‚¹ãƒˆæ•™å­¦é™¢å¤§å­¦"
    ]
}


async def search_universities(
    region: str = "",
    faculty: str = "",
    exam_type: str = "",
    use_common_test: str = "",
    deviation_score: str = "",
    institution_type: str = "",
    prefecture: str = "",
    name_keyword: str = "",
    common_test_score: str = "",
    external_english: str = "",
    required_subjects: str = "",
    tuition_max: str = "",
    scholarship: str = "",
    qualification: str = "",
    exam_schedule: str = "",
    progress_callback: Optional[Callable[[Dict[str, Any]], Awaitable[None]]] = None,
    university_callback: Optional[Callable[[dict], Awaitable[None]]] = None,
) -> List[dict]:
    # ... (ãƒ¡ã‚¤ãƒ³æ¤œç´¢é–¢æ•°ã¯å¤‰æ›´ãªã—)
    """
    Main search function
    Searches web and returns structured university data
    """
    logger.info(f"Starting university search with filters: region={region}, faculty={faculty}")

    async def _emit_progress(stage: str, detail: Optional[Dict[str, Any]] = None) -> None:
        if progress_callback is None:
            return
        payload = {"stage": stage}
        if detail:
            payload.update(detail)
        _debug_log(f"[search_universities] progress stage={stage} detail={detail}")
        await progress_callback(payload)

    # Initialize optimal model selection
    selected_model = await initialize_model()
    logger.info(f"Using AI model: {selected_model}")
    await _emit_progress("model_selected", {"model": selected_model})

    # Build search query
    query_parts = ["å¤§å­¦"]

    if region:
        query_parts.append(f"{region}åœ°æ–¹ å¤§å­¦")
    if prefecture:
        query_parts.append(f"{prefecture} å¤§å­¦")
    if faculty:
        query_parts.append(f"{faculty} å­¦éƒ¨")
    else:
        query_parts.append("å­¦éƒ¨ å…¥è©¦æƒ…å ±")
    if institution_type:
        query_parts.append(f"{institution_type} å¤§å­¦")
    if exam_type:
        query_parts.append(f"å…¥è©¦æ–¹å¼ {exam_type}")
    if use_common_test == "ã‚ã‚Š":
        query_parts.append("å…±é€šãƒ†ã‚¹ãƒˆåˆ©ç”¨")
    if use_common_test == "ãªã—":
        query_parts.append("å…±é€šãƒ†ã‚¹ãƒˆéåˆ©ç”¨")
    if deviation_score:
        query_parts.append(f"åå·®å€¤ {deviation_score}")
    if common_test_score:
        query_parts.append(f"å…±é€šãƒ†ã‚¹ãƒˆå¾—ç‚¹ç‡ {common_test_score}")
    if external_english == "ã‚ã‚Š":
        query_parts.append("è‹±èªå¤–éƒ¨è©¦é¨“ åˆ©ç”¨")
    if external_english == "ä¸è¦":
        query_parts.append("è‹±èªå¤–éƒ¨è©¦é¨“ ä¸è¦")
    if required_subjects:
        query_parts.append(f"å¿…è¦ç§‘ç›® {required_subjects}")
    if tuition_max:
        query_parts.append(f"å­¦è²»ä¸Šé™ {tuition_max}")
    if scholarship == "ã‚ã‚Š":
        query_parts.append("å¥¨å­¦é‡‘åˆ¶åº¦ ã‚ã‚Š")
    if qualification:
        query_parts.append(f"{qualification} å–å¾—å¯èƒ½")
    if name_keyword:
        query_parts.append(f"{name_keyword} å…¬å¼")

    if exam_schedule:
        query_parts.append(f"å…¥è©¦æ—¥ç¨‹ {exam_schedule}")

    query = " ".join(query_parts) + " å…¥è©¦æƒ…å ±"
    logger.info(f"Generated search query: {query}")
    await _emit_progress("query_built", {"query": query})

    # Search web across multiple reputable sources
    site_domains = [
        "passnavi.evidus.com",   # æ—ºæ–‡ç¤¾ãƒ‘ã‚¹ãƒŠãƒ“
        "keinet.ne.jp",          # æ²³åˆå¡¾ Kei-Net
        "manabi.benesse.ne.jp",  # ãƒ™ãƒãƒƒã‚» ãƒãƒŠãƒ“ã‚¸ãƒ§ãƒ³
        "www.toshin.com",        # æ±é€²
        "yozemi.ac.jp",          # ä»£ã€…æœ¨ã‚¼ãƒŸãƒŠãƒ¼ãƒ«
        "www.dnc.ac.jp",         # å¤§å­¦å…¥è©¦ã‚»ãƒ³ã‚¿ãƒ¼
    ]

    queries = [query] + [f"{query} site:{domain}" for domain in site_domains]

    # Add official university domain patterns (generic) for entrance info
    official_patterns = [
        "å…¥è©¦æƒ…å ±",
        "admissions",
        "å…¥è©¦ è¦é …",
        "å…¥è©¦æ¡ˆå†…",
        "entrance",
        "nyushi",
        "å…¥å­¦è©¦é¨“",
    ]
    for kw in official_patterns:
        queries.append(f"{query} site:*.ac.jp {kw}")

    # Add regional university specific queries for broader coverage
    if region and region in REGIONAL_UNIVERSITIES:
        regional_unis = REGIONAL_UNIVERSITIES[region][:15]  # Top 15 universities per region
        for uni_name in regional_unis:
            queries.append(f"{uni_name} {faculty if faculty else 'å­¦éƒ¨'} å…¥è©¦æƒ…å ±")
            if faculty:
                queries.append(f"{uni_name} {faculty} å…¥è©¦æƒ…å ± åå·®å€¤")
            queries.append(f"{uni_name} å…¥è©¦æ–¹å¼ site:*.ac.jp")

    # If a specific university keyword is provided, bias towards official pages
    if name_keyword:
        for kw in official_patterns:
            queries.append(f"{name_keyword} site:*.ac.jp {kw}")
        # Also add a general official bias without site restriction
        queries.append(f"{name_keyword} å…¬å¼ å…¥è©¦æƒ…å ±")

    # Limit queries to prevent excessive API calls
    queries = queries[:50]  # Maximum 50 queries to balance coverage and efficiency

    aggregated_results: List[dict] = []
    seen_urls = set()

    async def _run_single_query(idx: int, q: str) -> None:
        try:
            await _emit_progress("searching", {"current": idx, "total": len(queries), "query": q})
            results = await search_web(q)
            for item in results:
                url = item.get("url") or item.get("link") or ""
                if url and url not in seen_urls:
                    aggregated_results.append(item)
                    seen_urls.add(url)
        except Exception as exc:  # noqa: BLE001
            logger.warning(f"Search failed for query '{q}': {exc}")

    # Execute queries with controlled concurrency to improve throughput
    semaphore = asyncio.Semaphore(10)

    async def _bounded_query(idx: int, q: str) -> None:
        async with semaphore:
            await _run_single_query(idx, q)

    await asyncio.gather(*(_bounded_query(index, q) for index, q in enumerate(queries, start=1)))

    await _emit_progress("search_complete", {"results": len(aggregated_results)})

    # Prioritize trusted sources (PassNavi/Kei-Net), then official (*.ac.jp), then others
    def _priority(u: str) -> int:
        if not u:
            return 0
        if "passnavi.obunsha.co.jp" in u:
            return 200  # Increased priority for PassNavi
        if "keinet.ne.jp" in u:
            return 180  # Increased priority for Kei-Net
        if "www.dnc.ac.jp" in u:  # å¤§å­¦å…¥è©¦ã‚»ãƒ³ã‚¿ãƒ¼ï¼ˆå…¬å¼ï¼‰
            return 150
        if u.endswith(".ac.jp") or ".ac.jp/" in u:
            return 120
        if "yozemi.ac.jp" in u:  # ä»£ã€…æœ¨ã‚¼ãƒŸãƒŠãƒ¼ãƒ«ï¼ˆä¿¡é ¼ã§ãã‚‹äºˆå‚™æ ¡ï¼‰
            return 100
        return 10

    aggregated_results.sort(key=lambda r: _priority(r.get("url") or r.get("link") or ""), reverse=True)
    search_results = aggregated_results

    # Summarize with AI
    await _emit_progress("summarizing", {"sources": len(search_results)})
    joined_query = " | ".join(queries)
    raw_universities = await summarize_with_ai(search_results, joined_query)
    _debug_log(f"[search_universities] summarize_with_ai returned {len(raw_universities)} entries for '{joined_query[:80]}'")
    universities = [_normalize_university_entry(uni) for uni in raw_universities]
    for uni in universities:
        official = uni.get("officialUrl")
        if official and official not in uni["sources"]:
            uni["sources"].insert(0, official)
    await _emit_progress("summarize_complete", {"count": len(universities)})

    # Filter universities by search conditions using AI
    filters_dict = {
        "region": region,
        "faculty": faculty,
        "exam_type": exam_type,
        "use_common_test": use_common_test,
        "deviation_score": deviation_score,
        "institution_type": institution_type,
        "prefecture": prefecture,
        "name_keyword": name_keyword,
        "common_test_score": common_test_score,
        "external_english": external_english,
        "required_subjects": required_subjects,
        "tuition_max": tuition_max,
        "scholarship": scholarship,
        "qualification": qualification,
        "exam_schedule": exam_schedule,
    }
    universities = await filter_universities_by_conditions(universities, filters_dict, progress_callback, university_callback)

    # Deduplicate by (name, faculty, examType) keeping entries with preferred sources
    def _src_score(urls: list) -> int:
        score = 0
        for u in urls or []:
            if not isinstance(u, str):
                continue
            if "passnavi.obunsha.co.jp" in u:
                score += 100
            elif "keinet.ne.jp" in u:
                score += 90
            elif "www.dnc.ac.jp" in u:  # å¤§å­¦å…¥è©¦ã‚»ãƒ³ã‚¿ãƒ¼ï¼ˆå…¬å¼ï¼‰
                score += 85
            elif u.endswith(".ac.jp") or ".ac.jp/" in u:
                score += 80
            elif "yozemi.ac.jp" in u:  # ä»£ã€…æœ¨ã‚¼ãƒŸãƒŠãƒ¼ãƒ«ï¼ˆä¿¡é ¼ã§ãã‚‹äºˆå‚™æ ¡ï¼‰
                score += 75
            else:
                score += 10
        return score

    dedup: dict = {}
    for uni in universities:
        name = (uni.get("name") or "").strip()
        faculty_val = (uni.get("faculty") or "").strip()
        exam_val = (uni.get("examType") or "").strip()
        key = (name, faculty_val, exam_val)
        current_best = dedup.get(key)
        if current_best is None:
            dedup[key] = uni
        else:
            if _src_score(uni.get("sources")) > _src_score(current_best.get("sources")):
                dedup[key] = uni

    universities = list(dedup.values())

    # Sort by name, faculty, examType
    universities.sort(key=lambda x: ((x.get("name") or ""), (x.get("faculty") or ""), (x.get("examType") or "")))
    
    logger.info(f"University search completed, returning {len(universities)} results")
    await _emit_progress("completed", {"count": len(universities)})
    return universities


# --- å®Ÿè¡Œä¾‹ ---
async def main():
    # ğŸš¨ ã€ä¿®æ­£ç®‡æ‰€ã€‘ç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯ã¯ãã®ã¾ã¾
    if not os.getenv("HF_API_KEY"):
        print("ç’°å¢ƒå¤‰æ•° 'HF_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return
        
    if not os.getenv("TAVILY_API_KEY") and not os.getenv("SERPER_API_KEY"):
        print("ç’°å¢ƒå¤‰æ•° 'TAVILY_API_KEY' ã¾ãŸã¯ 'SERPER_API_KEY' ã®ã„ãšã‚Œã‹ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return
        
    print("--- å¤§å­¦æƒ…å ±æ¤œç´¢ã‚µãƒ¼ãƒ“ã‚¹ã‚’å®Ÿè¡Œä¸­ ---")
    
    # ä¾‹ã¨ã—ã¦ã€ç‰¹å®šã®æ¡ä»¶ã§æ¤œç´¢
    try:
        results = await search_universities(
            region="é–¢æ±",
            faculty="æƒ…å ±ç§‘å­¦éƒ¨",
            exam_type="ä¸€èˆ¬é¸æŠœ",
            deviation_score="65ä»¥ä¸Š"
        )
        print("\n--- æ¤œç´¢çµæœ (JSON) ---")
        print(json.dumps(results, indent=2, ensure_ascii=False))
        
    except Exception as e:
        print(f"\nãƒ¡ã‚¤ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    # éåŒæœŸå®Ÿè¡Œ
    # å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€ã“ã®éƒ¨åˆ†ã¯ã‚¦ã‚§ãƒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«çµ„ã¿è¾¼ã¾ã‚Œã¾ã™ã€‚
    try:
        asyncio.run(main())
    except Exception as e:
        print(f"æœ€ä¸Šä½ã®å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
"""
AI Chat Service
Provides career counseling using Hugging Face Chat Completions API
"""

import os
import logging
import json
import asyncio
from typing import AsyncIterator, Dict, List
import httpx

# ğŸ’¡ .envã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãŸã‚ã«dotenvãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’è¿½åŠ 
from dotenv import load_dotenv # ğŸ‘ˆ è¿½åŠ 

# ğŸš¨ ã€ä¿®æ­£ã€‘ç’°å¢ƒå¤‰æ•°ãƒ­ãƒ¼ãƒ‰
load_dotenv() # ğŸ‘ˆ è¿½åŠ : .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO) # å¿…è¦ã«å¿œã˜ã¦DEBUGã«å¤‰æ›´

# ğŸš¨ ã€ä¿®æ­£ç®‡æ‰€ã€‘Hugging Face Chat Completions API configuration
# ğŸ“ ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã«åˆã‚ã›ã¦URLã¨ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
HF_API_KEY = os.getenv("HF_API_KEY", "")
# Chat Completions APIã®URL
HUGGINGFACE_API_URL = "https://router.huggingface.co/v1/chat/completions"
# Chat Completions APIã§åˆ©ç”¨å¯èƒ½ãªæ—¥æœ¬èªã«å¼·ã„Instructãƒ¢ãƒ‡ãƒ«
HUGGINGFACE_MODEL_ID = os.getenv("HF_MODEL_ID", "MiniMaxAI/MiniMax-M2:novita") # ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã¨åŒã˜ãƒ¢ãƒ‡ãƒ«åã‚’ä½¿ç”¨

logger.info(f"Chat service initialized, using model: {HUGGINGFACE_MODEL_ID}")

# --- APIå‘¼ã³å‡ºã—é–¢æ•° ---
# ğŸš¨ ã€ä¿®æ­£ç®‡æ‰€ã€‘Hugging Face Chat Completions APIã®ã‚¯ã‚¨ãƒªé–¢æ•°
async def query_hf_inference_chat(messages: List[Dict[str, str]]) -> str:
    """
    Send chat messages to Hugging Face Chat Completions API and get response
    """
    if not HF_API_KEY:
        raise ValueError("Hugging Face API key not configured")
    
    headers = {
        "Authorization": f"Bearer {HF_API_KEY}",
        "Content-Type": "application/json"
    }
    
    # ğŸš¨ ã€ä¿®æ­£ç®‡æ‰€ã€‘ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’ Chat Completions API å½¢å¼ã«å¤‰æ›´
    payload = {
        "messages": messages, # 'messages' å½¢å¼ã®å…¥åŠ›ã‚’ãã®ã¾ã¾ä½¿ç”¨
        "model": HUGGINGFACE_MODEL_ID,
        "temperature": 0.7,
        "max_tokens": 1000, # Chat Completionsã§ã¯max_new_tokensã§ã¯ãªãmax_tokensã‚’ä½¿ç”¨
        "top_p": 0.9,
    }
    
    async with httpx.AsyncClient(timeout=60.0) as client:
        try:
            response = await client.post(
                HUGGINGFACE_API_URL, # ä¿®æ­£ã•ã‚ŒãŸURLã‚’ä½¿ç”¨
                headers=headers,
                json=payload,
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'choices' in result and result['choices'] and 'message' in result['choices'][0]:
                    # å¿œç­”ã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å†…å®¹ã‚’æŠ½å‡ºã—ã¦è¿”å´
                    return result['choices'][0]['message']['content'].strip()
                else:
                    logger.error(f"Unexpected response format: {result}")
                    raise ValueError("Unexpected response format from Hugging Face API")
            else:
                logger.error(f"HF Chat API error: {response.status_code} - {response.text}")
                response.raise_for_status()
                
        except Exception as e:
            logger.error(f"Error querying HF Chat API: {str(e)}")
            raise

# --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®ãƒãƒ£ãƒƒãƒˆãƒ­ã‚¸ãƒƒã‚¯é–¢æ•° ---
def _build_chat_messages(message: str, history: List[dict]) -> List[Dict[str, str]]:
    """Create chat completion payload messages shared across streaming and non-streaming flows."""
    messages: List[Dict[str, str]] = [
        {
            "role": "system",
            "content": """ã‚ãªãŸã¯æ—¥æœ¬ã®é«˜æ ¡ç”Ÿå‘ã‘ã®é€²è·¯ç›¸è«‡ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
ä»¥ä¸‹ã®ã‚¬ã‚¤ãƒ‰ãƒ©ã‚¤ãƒ³ã«å¾“ã£ã¦ã€è¦ªã—ã¿ã‚„ã™ãã€ã‹ã¤æ¤œç´¢æœ€é©åŒ–ã•ã‚ŒãŸææ¡ˆã‚’è¡Œã£ã¦ãã ã•ã„ï¼š

1. ç”Ÿå¾’ã®èˆˆå‘³ãƒ»é–¢å¿ƒã‚„å¾—æ„ç§‘ç›®ã‹ã‚‰ã€é©ã—ãŸå­¦éƒ¨ãƒ»å­¦ç§‘ã‚’ææ¡ˆã™ã‚‹
2. å…·ä½“çš„ãªå¤§å­¦åã‚’æŒ™ã’ã‚‹å ´åˆã¯ã€æœ‰åå¤§å­¦ã‚„åœ°åŸŸã‚’æ„è­˜ã—ãŸå€™è£œã‚’3-5æ ¡ç¨‹åº¦ç´¹ä»‹ã™ã‚‹
3. **å›ç­”ã¯100-200æ–‡å­—ç¨‹åº¦ã«ã¾ã¨ã‚ã€éåº¦ã«çŸ­ãã—ã™ããªã„**
4. å¿…è¦ã«å¿œã˜ã¦Markdownã®è¦‹å‡ºã—ãƒ»ç®‡æ¡æ›¸ããƒ»ç•ªå·ä»˜ããƒªã‚¹ãƒˆã‚’æ´»ç”¨ã—ã€æ§‹é€ åŒ–ã—ã¦åˆ†ã‹ã‚Šã‚„ã™ãæç¤ºã™ã‚‹
5. ç”Ÿå¾’ã®è³ªå•å†…å®¹ã«å¿œã˜ã¦ã€éƒ½é“åºœçœŒãƒ»åœ°æ–¹ãƒ»å‡ºé¡˜æ–¹å¼ãªã©æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã«æœ‰ç›Šãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è£œã„ã€æ„å›³ã‚’æ˜ç¢ºã«ã—ãŸä¸Šã§ææ¡ˆã™ã‚‹
6. å›ç­”ã¯å¿…ãšæ—¥æœ¬èªã§è¡Œã†
""",
        }
    ]

    for h in history[-3:]:
        messages.append({"role": "user", "content": h.get("question", "")})
        messages.append({"role": "assistant", "content": h.get("answer", "")})

    refined_prompt = (
        "ä»¥ä¸‹ã®è³ªå•ã«ç­”ãˆã‚‹å‰ã«ã€æ¤œç´¢ç²¾åº¦ã‚’é«˜ã‚ã‚‹ãŸã‚ã«å¿…è¦ãªåœ°åãƒ»å¤§å­¦åŒºåˆ†ãƒ»è©¦é¨“å½¢æ…‹ãªã©ã‚’å«ã‚€ã‚ˆã†ã«æ„å›³ã‚’æ•´ç†ã—ã¦ãã ã•ã„ã€‚"
        "ç®‡æ¡æ›¸ãã§æ¤œç´¢å‘ã‘ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è£œè¶³ã—ãŸä¸Šã§ã€ãã®å¾Œã«å›ç­”ã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚\n\n"
        f"è³ªå•: {message}"
    )

    messages.append({"role": "user", "content": refined_prompt})
    return messages


async def chat_with_ai(message: str, history: List[dict]) -> str:
    """
    Chat with AI for career counseling
    Uses conversation history for context
    """
    logger.info(f"Received chat message: {message[:100]}...")

    if not HF_API_KEY:
        logger.warning("No Hugging Face API key configured")
        return (
            "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ç¾åœ¨AIã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\n"
            "**HF_API_KEY** ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )

    messages = _build_chat_messages(message, history)

    try:
        logger.debug(f"Sending messages to Hugging Face: {messages}")
        ai_response = await query_hf_inference_chat(messages)

        ai_response = ai_response.replace('<s>', '').replace('</s>', '').strip()
        if len(ai_response) > 1000:
            ai_response = ai_response[:1000] + "..."

        logger.info("AI response generated successfully")
        return ai_response

    except Exception as e:
        logger.error(f"AI chat failed: {str(e)}")
        return (
            "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ãŒã€ç¾åœ¨AIã¨ã®ä¼šè©±ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
            "ã—ã°ã‚‰ãçµŒã£ã¦ã‹ã‚‰ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚"
            f"\n\nï¼ˆã‚¨ãƒ©ãƒ¼ã®è©³ç´°: {str(e)}ï¼‰"
        )


async def chat_with_ai_stream(message: str, history: List[dict]) -> AsyncIterator[str]:
    """Stream AI responses token-by-token for richer UX."""
    logger.info(f"Streaming chat message: {message[:100]}...")

    if not HF_API_KEY:
        logger.warning("No Hugging Face API key configured for streaming")
        yield (
            "ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚ç¾åœ¨AIã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚\n"
            "**HF_API_KEY** ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚"
        )
        return

    payload = {
        "messages": _build_chat_messages(message, history),
        "model": HUGGINGFACE_MODEL_ID,
        "temperature": 0.7,
        "max_tokens": 1000,
        "top_p": 0.9,
        "stream": True,
    }

    async with httpx.AsyncClient(timeout=None) as client:
        try:
            async with client.stream(
                "POST",
                HUGGINGFACE_API_URL,
                headers={
                    "Authorization": f"Bearer {HF_API_KEY}",
                    "Content-Type": "application/json",
                },
                json=payload,
            ) as response:
                response.raise_for_status()

                async for line in response.aiter_lines():
                    if not line:
                        continue
                    if line.startswith("data: "):
                        data_str = line.removeprefix("data: ").strip()
                        if data_str == "[DONE]":
                            break
                        try:
                            data = json.loads(data_str)
                        except json.JSONDecodeError:
                            logger.debug(f"Skipping non-JSON streaming line: {data_str}")
                            continue

                        delta = (
                            data.get("choices", [{}])[0]
                            .get("delta", {})
                            .get("content", "")
                        )
                        if delta:
                            yield delta

        except Exception as exc:  # noqa: BLE001
            logger.error(f"Streaming chat failed: {exc}")
            raise

# --- å®Ÿè¡Œä¾‹ ---
async def main():
    """
    ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®ãŸã‚ã®å®Ÿè¡Œé–¢æ•°
    """
    print("--- Hugging Face AIã‚­ãƒ£ãƒªã‚¢ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ å®Ÿè¡Œãƒ‡ãƒ¢ ---")
    
    # ğŸš¨ ã€ä¿®æ­£ç®‡æ‰€ã€‘ç’°å¢ƒå¤‰æ•°ã®ãƒã‚§ãƒƒã‚¯ã¯ãã®ã¾ã¾
    if not os.getenv("HF_API_KEY"):
        print("\nğŸš¨ **è­¦å‘Š:** ç’°å¢ƒå¤‰æ•° 'HF_API_KEY' ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚AIå¿œç­”ã¯ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã«ãªã‚Šã¾ã™ã€‚")
        return
        
    # ä¼šè©±å±¥æ­´ã®ä¾‹
    history = [
        {"question": "ç§ã¯ç†ç³»ç§‘ç›®ãŒå¾—æ„ã§ã€ç‰¹ã«ç‰©ç†ã¨æ•°å­¦ãŒå¥½ãã§ã™ã€‚", "answer": "ãã‚Œã¯ç´ æ™´ã‚‰ã—ã„ã§ã™ã­ï¼ç‰©ç†ã¨æ•°å­¦ãŒå¾—æ„ãªã‚‰ã€ç†å·¥å­¦éƒ¨ã®æ©Ÿæ¢°å·¥å­¦ç§‘ã‚„é›»æ°—é›»å­å·¥å­¦ç§‘ã€ã¾ãŸã¯æƒ…å ±ç§‘å­¦éƒ¨ãªã©ãŒç‰¹ã«ãŠã™ã™ã‚ã§ã™ã€‚"},
    ]
    
    user_message = "æ©Ÿæ¢°å·¥å­¦ã«èˆˆå‘³ãŒã‚ã‚Šã¾ã™ã€‚æœ‰åãªå¤§å­¦ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
    
    print("-" * 30)
    print(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼: **{user_message}**")
    print("-" * 30)
    
    try:
        response = await chat_with_ai(user_message, history)
        print(f"\nAIã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼:\n{response}")
    except Exception as e:
        print(f"\nå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    # éåŒæœŸå®Ÿè¡Œ
    # å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€ã“ã®éƒ¨åˆ†ã¯ã‚¦ã‚§ãƒ–ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã«çµ„ã¿è¾¼ã¾ã‚Œã¾ã™ã€‚
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nå®Ÿè¡Œã‚’ä¸­æ–­ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")